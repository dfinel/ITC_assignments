{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCTKKTgY1RXv"
   },
   "source": [
    "# Dimensionality Reduction Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kg9e12Y1RXz"
   },
   "source": [
    "In this exercise, you will be asked to build several Machine Learning models, while understanding the value of PCA dimensionality reduction. Make sure your code is readable, functional, documented and that you give elaborate explanations and some plots to go with your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvLXYrX81RX0"
   },
   "source": [
    "## Load the MNIST dataset attached to this exercise (it is already divided to train and test sets, load both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T15:11:33.531642Z",
     "start_time": "2019-07-08T15:11:33.523467Z"
    },
    "collapsed": true,
    "id": "8CsxwcPf1RX0"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv('/Users/danfinel/Downloads/mnist_train.csv')\n",
    "df_test = pd.read_csv('/Users/danfinel/Downloads/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loN033Jy5V6g",
    "outputId": "c8684a72-a4c5-4380-a0e0-0733f2ac4526"
   },
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoRj3mYu1RX4"
   },
   "source": [
    "## 1. Build a classifier of your choice on the given data (your features are the pixels), and evaluate it. Elaborate on the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "Bhcr7egj4CMp"
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns = ['label'])\n",
    "y_train = df_train.label\n",
    "X_test = df_test.drop(columns = ['label'])\n",
    "y_test = df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "PH1aTAgT1RX4",
    "outputId": "5ed64c82-fba4-4bdb-d4c4-596d7af867d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       980\n",
      "           1       0.96      0.96      0.96      1135\n",
      "           2       0.86      0.86      0.86      1032\n",
      "           3       0.82      0.86      0.84      1010\n",
      "           4       0.88      0.87      0.87       982\n",
      "           5       0.84      0.82      0.83       892\n",
      "           6       0.90      0.89      0.90       958\n",
      "           7       0.92      0.90      0.91      1028\n",
      "           8       0.82      0.80      0.81       974\n",
      "           9       0.84      0.85      0.85      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_rf = dt.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVp6Jsqe7FVf"
   },
   "source": [
    "Based on the metrics we get, the model performance is great with an accuracy of 0.88 and precison and recall for each value of the target variable > 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkTCSFk01RX5"
   },
   "source": [
    "## 2. Perform a PCA dimensionality reduction on the data, and re-train the same model on the new top k PCA-ed features. Evaluate the new model and elaborate on the performance of your model, and compare it to the performance of model without PCA.\n",
    "## The value of k is for you to choose, but it must be pretty small.  Try some different numbers, and explain why you chose that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "fH5zOHhF1RX6"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.decomposition import PCA\n",
    "ks = [3,4,5,6,7,8,9,10]\n",
    "best_acc = 0\n",
    "best_k = 0\n",
    "for k in ks:\n",
    "  pca = PCA(n_components = k)\n",
    "  pca.fit(X_train,y_train)\n",
    "  X_train_transformed = pca.transform(X_train)\n",
    "  X_test_transformed = pca.transform(X_test)\n",
    "\n",
    "  dt2 = DecisionTreeClassifier()\n",
    "  dt2.fit(X_train_transformed,y_train)\n",
    "  y_pred_dt_pca = dt2.predict(X_test_transformed)\n",
    "  acc = dt2.score(X_test_transformed,y_test)\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_acc = acc\n",
    "    best_k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhXuCLbjFIC3",
    "outputId": "4905c122-a914-4b3a-d1b4-326d7be32e00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.8233)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k,best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsPHWlzfFx3J"
   },
   "source": [
    "Based on the accuracy we get, we find that k = 10 seems to have the best accuracy for k between 3 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jw1zrKdpFgMc",
    "outputId": "f81604ca-eb94-4e33-c2c8-2042be5f9054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       980\n",
      "           1       0.96      0.97      0.96      1135\n",
      "           2       0.86      0.84      0.85      1032\n",
      "           3       0.77      0.79      0.78      1010\n",
      "           4       0.77      0.77      0.77       982\n",
      "           5       0.74      0.78      0.76       892\n",
      "           6       0.89      0.89      0.89       958\n",
      "           7       0.86      0.84      0.85      1028\n",
      "           8       0.76      0.73      0.75       974\n",
      "           9       0.72      0.72      0.72      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_dt_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDVC2EqaGDCF"
   },
   "source": [
    "The result we get are much lower than the model without PCA. The accuracy is lower and most ot recalls and precisions are lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqvozxI61RX7"
   },
   "source": [
    "## 3. Compare the model metrics that you got from question 2, to a model with random subset of regular features:\n",
    "- Use the same number of features k as you used in question 2.\n",
    "- The actual features used is full regular pixel features without PCA.  \n",
    "- But instead of using all such 784 features, use a random subset of size k of features from question 2.\n",
    "\n",
    "Elaborate on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "NRm5_H131RX7",
    "outputId": "38227abd-10a0-48d3-be6a-cea639f591f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51       980\n",
      "           1       0.27      0.92      0.42      1135\n",
      "           2       0.34      0.25      0.29      1032\n",
      "           3       0.38      0.46      0.41      1010\n",
      "           4       0.17      0.06      0.09       982\n",
      "           5       0.26      0.09      0.14       892\n",
      "           6       0.23      0.08      0.12       958\n",
      "           7       0.42      0.52      0.46      1028\n",
      "           8       0.20      0.10      0.14       974\n",
      "           9       0.33      0.16      0.22      1009\n",
      "\n",
      "    accuracy                           0.33     10000\n",
      "   macro avg       0.31      0.31      0.28     10000\n",
      "weighted avg       0.31      0.33      0.29     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random_indexes = np.sort(random.sample(range(784),best_k))\n",
    "X_train_random = X_train.loc[:,X_train.columns[random_indexes]]\n",
    "X_test_random = X_test.loc[:,X_test.columns[random_indexes]]\n",
    "dt3 = DecisionTreeClassifier()\n",
    "dt3.fit(X_train_random,y_train)\n",
    "y_pred_random_dt = dt3.predict(X_test_random)\n",
    "print(classification_report(y_test,y_pred_random_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyCLQGZ4K1Gd"
   },
   "source": [
    "We see that the result we get are very worse when we take random features. It shows the power of PCA for choosing the best features possible and the best coefficient of linearity for those features (on q3 we took all coefficient = 1 for the 10 features).\n",
    "\n",
    "However, as we are on a supervised learning problem, PCA is less efficient than keeping all the features with no transformation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
